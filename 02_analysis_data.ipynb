{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a1dccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "df = pd.read_csv('C:\\\\Users\\\\Hp\\\\Desktop\\\\MyWorkspaces\\\\My Analyst Project\\\\Hospital Data\\\\data\\\\csv\\\\FY_2022-2025.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ebe078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "# Flag missing ERRs (common for CABG / THA-TKA)\n",
    "missing = df.filter(like='ERR').isna().sum().sort_values(ascending=False)\n",
    "missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5f545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty_cols = [c for c in df.columns if 'Penalty indicator' in c]\n",
    "df['Any_Penalty'] = df[penalty_cols].eq('Y').any(axis=1)\n",
    "\n",
    "penalty_summary = (\n",
    "    df[penalty_cols + ['Any_Penalty']]\n",
    "    .melt(var_name='Condition', value_name='Penalty')\n",
    "    .assign(Condition=lambda x: x['Condition'].str.extract(r'for (.+?)\\s*$')[0])\n",
    "    .query(\"Penalty == 'Y'\")\n",
    "    .groupby('Condition').size()\n",
    "    .rename('Hospitals_Penalized')\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "penalty_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f9f03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['Payment reduction percentage'], bins=30, kde=True)\n",
    "plt.title('Distribution of Medicare Payment Reductions (%)')\n",
    "plt.show()\n",
    "\n",
    "top_10_penalized = (\n",
    "    df.nlargest(10, 'Payment reduction percentage')\n",
    "    [['Hospital CCN', 'Payment reduction percentage', 'Peer group assignment']]\n",
    ")\n",
    "top_10_penalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb556e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "peer_stats = (\n",
    "    df.groupby('Peer group assignment')\n",
    "      .agg(\n",
    "          Hospitals=('Hospital CCN', 'count'),\n",
    "          Avg_Payment_Reduction=('Payment reduction percentage', 'mean'),\n",
    "          Any_Penalty_Rate=('Any_Penalty', 'mean'),\n",
    "          Mean_DUAL=('Dual proportion', 'mean')\n",
    "      )\n",
    "      .round(3)\n",
    ")\n",
    "peer_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7a500a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build tidy long table of ERR & Penalty\n",
    "long = []\n",
    "for cond in ['AMI', 'COPD', 'HF', 'pneumonia', 'CABG', 'THA/TKA']:\n",
    "    long.append(\n",
    "        df[['Hospital CCN', 'Peer group assignment', f'ERR for {cond}', f'Penalty indicator for {cond}']]\n",
    "        .rename(columns={\n",
    "            f'ERR for {cond}': 'ERR',\n",
    "            f'Penalty indicator for {cond}': 'Penalty'\n",
    "        })\n",
    "        .assign(Condition=cond)\n",
    "    )\n",
    "long = pd.concat(long)\n",
    "\n",
    "# Ensure ERR is numeric and drop NaNs\n",
    "long['ERR'] = pd.to_numeric(long['ERR'], errors='coerce')\n",
    "long = long.dropna(subset=['ERR'])\n",
    "\n",
    "# Top 10 worst ERRs with penalties\n",
    "worst = (\n",
    "    long.query(\"Penalty == 'Y'\")\n",
    "        .nlargest(10, 'ERR')\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "worst[['Hospital CCN', 'Condition', 'ERR', 'Peer group assignment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cf0012",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric = df.select_dtypes(include='number').drop(columns=['Year'])  # constant\n",
    "corr = numeric.corr()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr, annot=False, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation matrix of numeric features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc919558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. High-priority hospitals (≥1.0% payment reduction + any penalty)\n",
    "priority = df[df['Payment reduction percentage'] >= 1.0]\n",
    "\n",
    "# 2. Peer groups with lowest performance\n",
    "underperforming_peers = peer_stats[peer_stats['Any_Penalty_Rate'] > 0.5]\n",
    "\n",
    "# 3. Conditions driving the most penalties\n",
    "conditions_to_watch = penalty_summary.head(3).index.tolist()\n",
    "\n",
    "print(\"ACTIONABLE INSIGHTS\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"• {len(priority)} hospitals face ≥1% payment reduction.\")\n",
    "print(f\"• Peer groups with >50% penalty rate: {underperforming_peers.index.tolist()}\")\n",
    "print(f\"• Top 3 conditions to target for improvement: {conditions_to_watch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad307762",
   "metadata": {},
   "source": [
    "1️⃣ ## Which hospitals lose the most Medicare dollars in absolute terms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241d6a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AMI-specific columns\n",
    "drg_col = 'DRG payment ratio for AMI'\n",
    "vol_col = 'Number of eligible discharges for AMI'\n",
    "\n",
    "# Ensure both are numeric\n",
    "df[drg_col] = pd.to_numeric(df[drg_col], errors='coerce')\n",
    "df[vol_col] = pd.to_numeric(df[vol_col], errors='coerce')\n",
    "\n",
    "# Dollar loss estimate\n",
    "df['AMI_DollarLoss'] = (1 - df[drg_col]).fillna(0) * df[vol_col].fillna(0)\n",
    "\n",
    "# Top 10 hospitals by estimated loss\n",
    "top_dollar_loss = (\n",
    "    df[['Hospital CCN', 'AMI_DollarLoss']]\n",
    "    .query(\"AMI_DollarLoss > 0\")\n",
    "    .sort_values('AMI_DollarLoss', ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "top_dollar_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5125a07",
   "metadata": {},
   "source": [
    "Peer-group median ERR vs. your hospital’s ERR – instant benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c2e7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_condition(condition='AMI'):\n",
    "    base = df[['Hospital CCN', 'Peer group assignment', f'ERR for {condition}']].dropna()\n",
    "\n",
    "    base[f'ERR for {condition}'] = pd.to_numeric(base[f'ERR for {condition}'], errors='coerce')\n",
    "\n",
    "    medians = base.groupby('Peer group assignment')[f'ERR for {condition}'].median()\n",
    "\n",
    "    base = base.merge(medians.rename(f'Median_ERR_{condition}'), on='Peer group assignment')\n",
    "\n",
    "    base['Above_Peer_Median'] = base[f'ERR for {condition}'] > base[f'Median_ERR_{condition}']\n",
    "    \n",
    "    return base[['Hospital CCN', f'ERR for {condition}', f'Median_ERR_{condition}', 'Above_Peer_Median']]\n",
    "\n",
    "benchmark_condition('AMI').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0dee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Any_Penalty', y='Dual proportion', data=df)\n",
    "plt.title('Dual-eligible share by penalty status')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1bd89d",
   "metadata": {},
   "source": [
    "\n",
    "4️⃣ ##### Smallest hospitals (Peer 1) that still escape penalties – best-practice candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f631b00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df['Peer group assignment'] == 1) & (~df['Any_Penalty'])\n",
    "good_small = (\n",
    "    df.loc[mask, ['Hospital CCN', 'Dual proportion']]\n",
    "      .nsmallest(10, 'Dual proportion')\n",
    ")\n",
    "good_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb4e7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_err = (\n",
    "    df[['Number of eligible discharges for AMI', 'ERR for AMI']]\n",
    "    .dropna()\n",
    "    .assign(**{'ERR for AMI': lambda x: pd.to_numeric(x['ERR for AMI'], errors='coerce')})\n",
    ")\n",
    "sns.regplot(data=vol_err, x='Number of eligible discharges for AMI', y='ERR for AMI')\n",
    "plt.title('AMI Volume vs ERR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acddeaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worst_metric_per_hospital():\n",
    "    cols = [c for c in df.columns if 'ERR' in c and 'Penalty' not in c]\n",
    "    tidy = (df[['Hospital CCN'] + cols]\n",
    "            .melt(id_vars='Hospital CCN', var_name='Metric', value_name='ERR')\n",
    "            .dropna())\n",
    "    tidy['ERR'] = pd.to_numeric(tidy['ERR'], errors='coerce')\n",
    "    # Highest ERR per hospital\n",
    "    return (tidy.sort_values('ERR', ascending=False)\n",
    "                .drop_duplicates('Hospital CCN')\n",
    "                .head(15))\n",
    "worst_metric_per_hospital()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8f0b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "penalty_heatmap = (\n",
    "    long.assign(Penalty=lambda x: x['Penalty'] == 'Y')\n",
    "        .groupby(['Condition', 'Peer group assignment'])['Penalty']\n",
    "        .mean()\n",
    "        .unstack(fill_value=0)\n",
    ")\n",
    "sns.heatmap(penalty_heatmap, annot=True, fmt='.1%', cmap='Reds')\n",
    "plt.title('Penalty rate by Condition & Peer Group')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a08ea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_condition(condition='HF'):\n",
    "    sub = df[['Hospital CCN', 'Peer group assignment', f'ERR for {condition}']].dropna()\n",
    "    sub[f'ERR for {condition}'] = pd.to_numeric(sub[f'ERR for {condition}'], errors='coerce')\n",
    "    sub['z_ERR'] = (sub.groupby('Peer group assignment')[f'ERR for {condition}']\n",
    "                      .transform(lambda x: (x - x.mean()) / x.std()))\n",
    "    return sub.sort_values('z_ERR', ascending=False).head(10)\n",
    "z_score_condition('HF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c97c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = ['ERR for AMI', 'ERR for HF', 'ERR for COPD', 'Dual proportion']\n",
    "\n",
    "# Build clean numeric matrix\n",
    "Xy = df[features + ['Any_Penalty']].copy()\n",
    "Xy[features] = Xy[features].apply(pd.to_numeric, errors='coerce')\n",
    "Xy = Xy.dropna()                       # <- remove any NaN rows\n",
    "X = Xy[features]\n",
    "y = Xy['Any_Penalty'].astype(int)\n",
    "\n",
    "# Model\n",
    "clf = LogisticRegression(max_iter=1000).fit(StandardScaler().fit_transform(X), y)\n",
    "\n",
    "# Coefficients\n",
    "coef = pd.Series(clf.coef_[0], index=features).sort_values(key=abs, ascending=False)\n",
    "coef"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "readmission",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
